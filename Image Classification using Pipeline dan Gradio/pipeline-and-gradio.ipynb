{"cells":[{"cell_type":"markdown","metadata":{"id":"VFa5VyVNPCJY"},"source":["# Project: Image Classification using Pipeline dan Gradio"]},{"cell_type":"markdown","metadata":{"id":"0Qg7V4zoPCJi"},"source":["**Description:**\n","\n","Welcome to your new assignment! In this project, you will have the opportunity to apply the knowledge and skills you've learned in class. The task at hand is to create an image classification project that predicts a person's age based on their photograph. You will be utilizing the power of machine learning pipelines to streamline your workflow and effectively manage the different stages of this project, from data preprocessing to model training and evaluation.\n","\n","Remember, the goal of this assignment is not just to build a model that makes accurate predictions, but also to understand the process of developing a machine-learning pipeline and the role each component plays in this process.\n","\n","We encourage you to be creative, explore different strategies, and most importantly, have fun while learning. We can't wait to see the innovative solutions you come up with! Best of luck!"]},{"cell_type":"markdown","metadata":{"id":"ZysTKHbGioh8"},"source":["## Student Identity"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"i8BlcSWzioi3","executionInfo":{"status":"ok","timestamp":1694587164227,"user_tz":-420,"elapsed":13,"user":{"displayName":"Rayhan Ozzy Ertarto","userId":"14941625543231200817"}}},"outputs":[],"source":["# @title #### Student Identity\n","student_id = \"REAN6EHF\" # @param {type:\"string\"}\n","name = \"Rayhan Ozzy Ertarto\" # @param {type:\"string\"}\n","drive_link = \"https://drive.google.com/drive/u/0/folders/1UmQuFGXN9G8XhlE3MtXi4Q_BDhJ1gv8a\"  # @param {type:\"string\"}"]},{"cell_type":"markdown","metadata":{"id":"vJWjH2kGV49k"},"source":["## Installation and Import Package"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"8wWESOr0PCJk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694587212635,"user_tz":-420,"elapsed":48419,"user":{"displayName":"Rayhan Ozzy Ertarto","userId":"14941625543231200817"}},"outputId":"ce44bed1-b2b2-4495-edcb-fa34a5c5bfb8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: rggrader in /usr/local/lib/python3.10/dist-packages (0.1.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from rggrader) (2.31.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from rggrader) (1.5.3)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rggrader) (9.4.0)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->rggrader) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->rggrader) (2023.3.post1)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas->rggrader) (1.23.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->rggrader) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->rggrader) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->rggrader) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->rggrader) (2023.7.22)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->rggrader) (1.16.0)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.33.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"]}],"source":["# Install necessary packages\n","!pip install rggrader\n","from rggrader import submit, submit_image\n","\n","# Put your code here:\n","import requests\n","import torch\n","import io\n","\n","from PIL import Image\n","from torch.nn.functional import softmax\n","\n","!pip install transformers\n","from transformers import ViTImageProcessor, ViTForImageClassification\n","# ---- End of your code ----"]},{"cell_type":"markdown","metadata":{"id":"4_mbLFq9Vvcg"},"source":["## Pipeline"]},{"cell_type":"markdown","metadata":{"id":"Io4CCbvZ-220"},"source":["**Task 1: Image Classification using Hugging Face's Model**\n","\n","In this first task, your task is to develop an image classification pipeline that takes **an image URL as input**, displays the image, and uses the Hugging Face's model to predict the age of the person in the image. You can get the model [here](https://huggingface.co/nateraw/vit-age-classifier).\n","\n","Here are the key steps that you might be able to follow:\n","\n","1. **Image URL Input:** Your program should accept an image URL as input. Make sure to handle potential issues with invalid URLs or inaccessible images.\n","2. **Image Display:** Display the image from the URL in your notebook. This will provide a visual confirmation that the correct image is being processed.\n","3. **Model Loading and Prediction:** Load the 'nateraw/vit-age-classifier' model from Hugging Face's model hub and pass the image URL to the model to obtain the prediction. The model should predict the age of the person in the image.\n","4. **Output Display:** Display the output from the model in a clear and understandable manner.\n","\n","## Submission\n","\n","- What percentage is the person in this picture (https://images.unsplash.com/photo-1596392927852-2a18c336fb78?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=1280&q=80) is between age of \"3-9\"?\n","\n","Submit in the numeric format up to 5 digits behind the decimal point. For example in below output:\n","\n","```\n","{'0-2': '0.00152',\n"," '3-9': '0.00105',\n"," '10-19': '0.02567',\n"," '20-29': '3.32545',\n"," '30-39': '51.75200',\n"," '40-49': '40.24234',\n"," '50-59': '4.47803',\n"," '60-69': '0.17092',\n"," 'more than 70': '0.00304'}\n","```\n","\n","The answer would be `0.00105`."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"H5LA1LcdPCJm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694587212636,"user_tz":-420,"elapsed":82,"user":{"displayName":"Rayhan Ozzy Ertarto","userId":"14941625543231200817"}},"outputId":"33f55f4b-f112-4d70-eb04-cf6c3dbf6315"},"outputs":[{"output_type":"stream","name":"stdout","text":["80.55308\n"]}],"source":["# @title #### 01. Image Classification using Hugging Face's Model\n","\n","# Put your code here:\n","\n","# Define the image URL\n","image_url = \"https://images.unsplash.com/photo-1596392927852-2a18c336fb78?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=1280&q=80\"\n","\n","# Load the image from the URL\n","response = requests.get(image_url)\n","image = Image.open(io.BytesIO(response.content))\n","\n","# Display the image\n","image.show()\n","\n","# Load the model and preprocess the image\n","model_name = \"nateraw/vit-age-classifier\"\n","transforms = ViTImageProcessor.from_pretrained(model_name)\n","model = ViTForImageClassification.from_pretrained(model_name)\n","\n","# Preprocess the image\n","inputs = transforms(images=image, return_tensors=\"pt\")\n","\n","# Make predictions\n","with torch.no_grad():\n","    logits = model(**inputs).logits\n","\n","# Post-process predictions\n","proba = softmax(logits, dim=1)[0]\n","preds = torch.argmax(proba).item()\n","age_range = [\"0-2\", \"3-9\", \"10-19\", \"20-29\", \"30-39\", \"40-49\", \"50-59\", \"60-69\", \"more than 70\"]\n","percentage_age_3_9 = proba[age_range.index(\"3-9\")].item() * 100\n","\n","# Display the result\n","print(f\"{percentage_age_3_9:.5f}\")\n","\n","# ---- End of your code ----"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"La_Uvs29-221","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1694587212638,"user_tz":-420,"elapsed":69,"user":{"displayName":"Rayhan Ozzy Ertarto","userId":"14941625543231200817"}},"outputId":"73839632-ccf7-4856-e3c2-0ae1a6975883"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Assignment successfully submitted'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}],"source":["# Submit Method\n","assignment_id = \"00_pipeline_and_gradio\"\n","question_id = \"01_image_classification_using_hugging_faces_model\"\n","answer = \"80.55308\" # Put your answer here\n","submit(student_id, name, assignment_id, answer, question_id, drive_link)"]},{"cell_type":"markdown","metadata":{"id":"5ZBnPIJdVlYG"},"source":["## Pipeline and Gradio"]},{"cell_type":"markdown","metadata":{"id":"B2wOiPqDiojo"},"source":["**Task 2: Image Classification using Hugging Face's Model and Gradio**\n","\n","In this second task, you will create a user-friendly interface using Gradio for your image classification pipeline that you created in Task 1. The difference with task 1 is, that in this task, you use **image files as input**, process them through the Hugging Face model, and display predictions output. The output displayed is **only the results with the highest `score`**.\n","\n","Here are the key steps that you might be able to follow:\n","\n","1. **Image Input:** Create a function to accept an image file as input. The image should be in a format that can be processed by the model.\n","2. **Model Loading and Prediction:** Load the model from Hugging Face's model hub and pass the image to the model to obtain the prediction. The model predicts the age of the person in the image.\n","3. **Gradio Interface:** Use Gradio to create a user-friendly interface for your application. The interface should allow users to upload an image file, and it should display the model's output in a clear and understandable manner.\n","4. **Interface Launch:** Launch the Gradio interface. Make sure that the interface is accessible and easy to use.\n","\n","## Submisssion\n","\n","![Upload colab](https://lh3.googleusercontent.com/drive-viewer/AITFw-wMsYV4Al6vaol_q2ipMbrdfZdBm4VNaFGjeBv6oW42hGuwoM-Hg4jDc3dRM10IjZy2LmSY1F8btONIJiYEQMGUvoxgaw=s2560)\n","\n","You need to submit screenshot of your Gradio's app. In Google Colab you can just use the \"Folder\" sidebar and click the upload button. Make sure your screenshot match below requirements:\n","\n","- You should upload a person's image to that app\n","- The score should be included at the screenshot\n"]},{"cell_type":"code","source":["!pip install gradio"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_aMvrYelhsvo","executionInfo":{"status":"ok","timestamp":1694587212639,"user_tz":-420,"elapsed":65,"user":{"displayName":"Rayhan Ozzy Ertarto","userId":"14941625543231200817"}},"outputId":"fe738782-3ff3-47d7-e449-175ac244fb55"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (3.44.0)\n","Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n","Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n","Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio) (0.103.1)\n","Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.3.1)\n","Requirement already satisfied: gradio-client==0.5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.5.0)\n","Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.0)\n","Requirement already satisfied: huggingface-hub>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.17.1)\n","Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n","Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.2)\n","Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.3)\n","Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n","Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.23.5)\n","Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.9.7)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (23.1)\n","Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n","Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.10.12)\n","Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n","Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.6)\n","Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n","Requirement already satisfied: requests~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.31.0)\n","Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n","Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.5.0)\n","Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.23.2)\n","Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (11.0.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.5.0->gradio) (2023.6.0)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.0)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio) (3.12.2)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio) (4.66.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.42.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.3.post1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (2023.7.22)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (8.1.7)\n","Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (0.14.0)\n","Requirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (3.7.1)\n","Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (0.27.0)\n","Requirement already satisfied: httpcore<0.19.0,>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (0.18.0)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.3.0)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi->gradio) (1.1.3)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.1.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.7.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.30.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.10.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n"]}]},{"cell_type":"code","execution_count":8,"metadata":{"id":"fsMSIbrwTKuB","colab":{"base_uri":"https://localhost:8080/","height":611},"executionInfo":{"status":"ok","timestamp":1694587487889,"user_tz":-420,"elapsed":10310,"user":{"displayName":"Rayhan Ozzy Ertarto","userId":"14941625543231200817"}},"outputId":"a3056d33-8c03-4a21-e329-9679ae23059a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","Running on public URL: https://f98c568f5e8a113291.gradio.live\n","\n","This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://f98c568f5e8a113291.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":8}],"source":["# @title #### 02. Image Classification using Hugging Face's Model and Gradio\n","\n","# Put your code here:\n","\n","#import requests\n","import gradio as gr\n","import json\n","\n","# Load the model and preprocess the image\n","model_name = \"nateraw/vit-age-classifier\"\n","transforms = ViTImageProcessor.from_pretrained(model_name)\n","model = ViTForImageClassification.from_pretrained(model_name)\n","\n","def predict_age(image):\n","  # Transform our image and pass it through the model\n","  inputs = transforms(image, return_tensors='pt')\n","  output = model(**inputs)\n","  # Predicted Class probabilities\n","  proba = output.logits.softmax(1)\n","  preds = proba.argmax(1)\n","  age_range = [\"0-2\", \"3-9\", \"10-19\", \"20-29\", \"30-39\", \"40-49\", \"50-59\", \"60-69\", \"more than 70\"]\n","  return json.dumps({'score': proba.squeeze()[preds].item(), 'label': age_range[preds.item()]})\n","\n","# Create the Gradio interface\n","iface = gr.Interface(\n","    fn=predict_age,\n","    inputs=\"image\",\n","    outputs=\"json\",\n","    title=\"Age Prediction from Image\",\n","    description=\"Upload an image to predict the age of the person in the image.\"\n",")\n","\n","# Launch the Gradio interface\n","iface.launch(share=True)\n","\n","# ---- End of your code ----"]},{"cell_type":"markdown","metadata":{"id":"iooYxZRr-222"},"source":["Example of Expected Output:\n","\n","![gradio-result](https://storage.googleapis.com/rg-ai-bootcamp/project-3-pipeline-and-gradio/gradio-result.png)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"c2tUQTyt-222","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1694587518014,"user_tz":-420,"elapsed":9829,"user":{"displayName":"Rayhan Ozzy Ertarto","userId":"14941625543231200817"}},"outputId":"0b9e52cd-b21d-4060-b797-d7aa2d60c7e4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Assignment successfully submitted'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":9}],"source":["# Submit Method\n","question_id = \"02_image_classification_using_hugging_faces_model_and_gradio\"\n","submit_image(student_id, question_id, '/content/submission.jpg')\n"]},{"cell_type":"markdown","metadata":{"id":"IIYX1tCa-223"},"source":["> Note: If your submission for Task-2 did not run (After you run it never changes from \"*\" to a number), stop the Code block that's running the Gradio app, then the submission will run. To stop the Code block, you can click on the Code block and then click the stop button."]}],"metadata":{"colab":{"provenance":[{"file_id":"1zu7V_8m_2c9pWynngCeUJJ5dMggu12j0","timestamp":1694354908217}],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}