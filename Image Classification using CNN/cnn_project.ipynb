{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rayhanozzy/Mastering-AI/blob/main/Image%20Classification%20using%20CNN/cnn_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0fd75ab4-1ea8-40d6-b52c-99bee57053ca",
      "metadata": {
        "id": "0fd75ab4-1ea8-40d6-b52c-99bee57053ca"
      },
      "source": [
        "# CNN - Project"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "194d8da1-20e4-4b61-b508-8e34c682a480",
      "metadata": {
        "id": "194d8da1-20e4-4b61-b508-8e34c682a480"
      },
      "source": [
        "## Project Description\n",
        "\n",
        "In this CNN Project, you will create your own custom Image Classification. You can collect a dataset of images you are interested in and train a CNN model to differentiate between them. For example, a model could be trained to distinguish between different types of birds, cars, plants, or any other topic of interest."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9dad0abc-34ef-44db-9a88-32d9d8ab2fbe",
      "metadata": {
        "id": "9dad0abc-34ef-44db-9a88-32d9d8ab2fbe"
      },
      "outputs": [],
      "source": [
        "#Write any package/module installation that you need here\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc07a2ba-cefc-425f-b86e-2f554b98bd4f",
      "metadata": {
        "id": "bc07a2ba-cefc-425f-b86e-2f554b98bd4f"
      },
      "source": [
        "## Task-1 Load the dataset\n",
        "\n",
        "In this task, you will prepare and load your dataset. **You can choose any dataset you want**, make sure the data is diverse and large enough to prevent overfitting and improve the model's ability to generalize.\n",
        "\n",
        "If you are using images from the internet, **please respect copyright and privacy laws**. Creative Commons licenses or public domain images are a safe bet, and many APIs (like the Unsplash API) provide access to a large number of such images."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26150053-ddb0-447a-8def-efab3f75d336",
      "metadata": {
        "id": "26150053-ddb0-447a-8def-efab3f75d336"
      },
      "source": [
        "### 1.1 Optional Custom Dataset\n",
        "Provided below is a custom dataset template that you may want to use for your code. It's completely optional.\n",
        "\n",
        "Alternatively, you can review the material on Data Augmentation or read the Pytorch tutorial https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#creating-a-custom-dataset-for-your-files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c598c9e0-31fe-4c13-956b-49c0033a39e0",
      "metadata": {
        "id": "c598c9e0-31fe-4c13-956b-49c0033a39e0"
      },
      "outputs": [],
      "source": [
        "#an example of creating our own custom dataset, you can use this if you want/need. Completely optional.\n",
        "import os\n",
        "import pandas as pd\n",
        "from torchvision.io import read_image\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
        "        self.img_labels = pd.read_csv(annotations_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "        image = read_image(img_path)\n",
        "        label = self.img_labels.iloc[idx, 1]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0abe9d36-5f0f-4e71-a24d-c5acea2c3735",
      "metadata": {
        "id": "0abe9d36-5f0f-4e71-a24d-c5acea2c3735"
      },
      "source": [
        "### 1.2 Write your code in the block below\n",
        "\n",
        "In the code block below, prepare and load your dataset. Please include data preprocessing steps such as dividing the dataset into training, validation, and test sets, or data augmentation techniques that you used if any in this section. Do not put the code to build your model here.\n",
        "\n",
        "Some techniques you may use:\n",
        "- Find and load existing dataset from Huggingface or Kaggle. (Easy)\n",
        "- Create your own custom dataset from the images you have in your possesion or internet search and load the dataset. (Hard)\n",
        "- Etc.\n",
        "\n",
        "Hint:\n",
        "- Usually the dataset are loaded into train_dataset and test_dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your data preprocessing code here\n",
        "# Define data transformations\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "# Load CIFAR-10 data using torchvision.datasets\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)\n",
        "\n",
        "# Use Data Loader\n",
        "train_loader = DataLoader(train_dataset, batch_size=100, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=100, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5RV64czdgYx",
        "outputId": "0e7b9273-b38d-437a-f70a-1e4ed4422043"
      },
      "id": "w5RV64czdgYx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:05<00:00, 30292177.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be3e5a65-0562-408a-9b9d-738e8efd825e",
      "metadata": {
        "id": "be3e5a65-0562-408a-9b9d-738e8efd825e"
      },
      "source": [
        "## Task-2 Build your model\n",
        "\n",
        "In this task, you will now build and save your model. You can either create your own CNN model or choose any pretrained model that you feel is most appropriate for your dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3683681f-2bbc-4c9d-9d5b-fb5b86dac054",
      "metadata": {
        "id": "3683681f-2bbc-4c9d-9d5b-fb5b86dac054"
      },
      "source": [
        "### 2.1 Write your code in the block below\n",
        "\n",
        "In the code block below, write the code to **create your model, either from scratch or fine tuning a pretrained model**. You will need to write the code for your model definition, such as the layers used, loss function and optimizer. Please include also the training and validation loops.\n",
        "\n",
        "Make sure you **save your model to a file** and **measure the accuracy of your model**, as this will be submitted for this task.\n",
        "\n",
        "Some techniques you may use:\n",
        "- Use pretrained model. (Easy)\n",
        "- Create a CNN model from scratch. (Hard)\n",
        "- Etc.\n",
        "\n",
        "Hint:\n",
        "- Use GPU in Google Colab, it significantly improves the time taken for training, compared to CPU.\n",
        "- **Google Colab GPU usage for free-tier have a limit**, which is unknown, so I suggest you try out in CPU mode that your code works without error, then use GPU for traininig.\n",
        "- If you are going to upload to Huggingface by using the Transformer Trainer during training, make sure you use the Huggingface method. Refer to Transfer Learning section or read the documentation here: https://huggingface.co/docs/transformers/model_sharing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Write your code to build your model here\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Define the CNN model\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(CNNModel, self).__init__()  # Add parentheses to super()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(128 * 4 * 4, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# Initialize model and set hyperparameters\n",
        "model = CNNModel(num_classes=10)  # CIFAR-10 has 10 classes\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}, Loss: {running_loss / len(train_loader)}\")\n",
        "\n",
        "# Validation loop\n",
        "model.eval()\n",
        "predictions = []\n",
        "true_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        predictions.extend(predicted.cpu().numpy())\n",
        "        true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "accuracy = accuracy_score(true_labels, predictions)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), \"cifar10_cnn_model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHLkGB69VRZl",
        "outputId": "8166889f-fd09-49ac-9645-5aca8886c1e7"
      },
      "id": "VHLkGB69VRZl",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.493749065876007\n",
            "Epoch 2, Loss: 1.0760661284923554\n",
            "Epoch 3, Loss: 0.8873490419387817\n",
            "Epoch 4, Loss: 0.7633965603113174\n",
            "Epoch 5, Loss: 0.678139275252819\n",
            "Epoch 6, Loss: 0.6003034115433693\n",
            "Epoch 7, Loss: 0.5341852638721466\n",
            "Epoch 8, Loss: 0.47509050795435903\n",
            "Epoch 9, Loss: 0.4216607447564602\n",
            "Epoch 10, Loss: 0.38042396780848503\n",
            "Epoch 11, Loss: 0.3357211081981659\n",
            "Epoch 12, Loss: 0.304189172655344\n",
            "Epoch 13, Loss: 0.2763716998696327\n",
            "Epoch 14, Loss: 0.2512572718858719\n",
            "Epoch 15, Loss: 0.2253542990088463\n",
            "Epoch 16, Loss: 0.20472171010077\n",
            "Epoch 17, Loss: 0.19390727688372136\n",
            "Epoch 18, Loss: 0.18862871715426446\n",
            "Epoch 19, Loss: 0.1721483232676983\n",
            "Epoch 20, Loss: 0.1602536598071456\n",
            "Epoch 21, Loss: 0.15414341182261707\n",
            "Epoch 22, Loss: 0.14538057327270507\n",
            "Epoch 23, Loss: 0.14360643276572227\n",
            "Epoch 24, Loss: 0.13911765625700354\n",
            "Epoch 25, Loss: 0.13086320772767068\n",
            "Epoch 26, Loss: 0.12944770084694027\n",
            "Epoch 27, Loss: 0.1256429310925305\n",
            "Epoch 28, Loss: 0.11906204950809479\n",
            "Epoch 29, Loss: 0.11849810162745417\n",
            "Epoch 30, Loss: 0.11842555309832097\n",
            "Epoch 31, Loss: 0.11538787026889623\n",
            "Epoch 32, Loss: 0.11166217869706452\n",
            "Epoch 33, Loss: 0.10469111868739128\n",
            "Epoch 34, Loss: 0.10051628269441426\n",
            "Epoch 35, Loss: 0.10899521348252893\n",
            "Epoch 36, Loss: 0.1025554221458733\n",
            "Epoch 37, Loss: 0.0983673202674836\n",
            "Epoch 38, Loss: 0.09900508718378842\n",
            "Epoch 39, Loss: 0.10056443926505744\n",
            "Epoch 40, Loss: 0.10315536007471382\n",
            "Epoch 41, Loss: 0.09531115510128438\n",
            "Epoch 42, Loss: 0.09799609003495426\n",
            "Epoch 43, Loss: 0.09725989759154617\n",
            "Epoch 44, Loss: 0.0980572472140193\n",
            "Epoch 45, Loss: 0.08382357496162876\n",
            "Epoch 46, Loss: 0.09749392102472484\n",
            "Epoch 47, Loss: 0.08987539540603758\n",
            "Epoch 48, Loss: 0.08957108066789805\n",
            "Epoch 49, Loss: 0.08943765836767853\n",
            "Epoch 50, Loss: 0.08827107595279812\n",
            "Accuracy: 77.23%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "156bff33-3226-4366-8ea0-df0b788f9861",
      "metadata": {
        "id": "156bff33-3226-4366-8ea0-df0b788f9861"
      },
      "source": [
        "## Task-3 Model Inference\n",
        "\n",
        "In this task, you will be exercising the application of your model, or as it's commonly referred to in AI terminology, you will be performing inference using your model.\n",
        "\n",
        "Simply load your saved model from Task-2 and create an inference for the model. Where you'll feed an image as input and the model will output the label as well as the percentage of confidence for the label."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd2313b4-c6f6-4305-be72-f21cdf531132",
      "metadata": {
        "id": "cd2313b4-c6f6-4305-be72-f21cdf531132"
      },
      "source": [
        "### 3.1 Write your code in the block below\n",
        "\n",
        "In the code block below write the code to use the model you created in Task-2. Load the model and input image, afterwards, show the result of the label/class together with confidence level in percentage as well as the input image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9120366-86dc-4314-ba9d-66f60ae5a884",
      "metadata": {
        "id": "c9120366-86dc-4314-ba9d-66f60ae5a884",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "outputId": "e30cd39b-1f40-40dc-e718-13ceb3aebab4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Write your code for inference here\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load your trained model\n",
        "model = CNNModel(num_classes=10)  # Replace with the actual model you trained\n",
        "model.load_state_dict(torch.load(\"/content/cifar10_cnn_model.pth\"))  # Load the saved model file\n",
        "\n",
        "# Define data transformations for the input image\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),  # Resize to match the model's input size\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize the image\n",
        "])\n",
        "\n",
        "# Load and preprocess the input image\n",
        "input_image = Image.open(\"/content/cat3.jpg\")  # Replace with the path to your input image\n",
        "input_image = transform(input_image)  # Apply transformations\n",
        "\n",
        "# Perform inference\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    output = model(input_image.unsqueeze(0))  # Add batch dimension\n",
        "\n",
        "# Get the predicted label and confidence\n",
        "_, predicted = torch.max(output, 1)\n",
        "confidence = torch.nn.functional.softmax(output, dim=1)[0] * 100  # Convert to percentage\n",
        "\n",
        "# Define class labels (replace with your own class labels)\n",
        "class_labels = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
        "\n",
        "# Display the result\n",
        "plt.imshow(input_image.permute(1, 2, 0))  # Show the input image\n",
        "predicted_label = class_labels[predicted.item()]  # Convert tensor to Python scalar\n",
        "confidence_value = confidence[predicted].item()  # Convert tensor to Python scalar\n",
        "plt.title(f'Predicted Label: {predicted_label}, Confidence: {confidence_value:.2f}%')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a021cd5-9c96-48d9-834d-18d37ba76824",
      "metadata": {
        "id": "2a021cd5-9c96-48d9-834d-18d37ba76824"
      },
      "source": [
        "## Task-4 Model Publishing\n",
        "\n",
        "In this task, you will push your model to Huggingface. Once you've pushed your model to the Hugging Face Model Hub, you'll have a link that points directly to your model's page. You can share this link with others, and they can use it to directly load your model for their own uses."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9cbd245-e9f7-4fdb-bc2c-1ca8c63af516",
      "metadata": {
        "id": "f9cbd245-e9f7-4fdb-bc2c-1ca8c63af516"
      },
      "source": [
        "### 4.1 Write your code in the block below\n",
        "\n",
        "In the code block below, write the code to push your model to Huggingface. There are several methods to do this, please refer to the documentation: https://huggingface.co/docs/transformers/model_sharing\n",
        "\n",
        "Some techniques you may use:\n",
        "- If you use the Transformer Trainer during the training loop when you create your model above, then you can simply put your `trainer.push_to_hub()` here.\n",
        "- You can also use the web interface on Huggingface.\n",
        "\n",
        "Hint:\n",
        "- Remember to login first to your Huggingface account.\n",
        "- If you are pushing programmaticaly, then use the huggingface-cli to login."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca04df60-d131-4108-88ae-18c253cfa1ba",
      "metadata": {
        "id": "ca04df60-d131-4108-88ae-18c253cfa1ba"
      },
      "outputs": [],
      "source": [
        "#Write your code for publishing here\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}